# ğŸ§© GenRec-Factory æ•°æ®å¤„ç†ä¸Embedding

æœ¬é¡¹ç›®æä¾›ä» **åŸå§‹æ•°æ®ä¸‹è½½ â†’ æ•°æ®é¢„å¤„ç† â†’ æ–‡æœ¬ä¸å›¾åƒ Embedding ç”Ÿæˆ â†’ å¤šæ¨¡æ€èåˆ** çš„ä¸€ç«™å¼å¤„ç†è„šæœ¬ã€‚  
ä»¥ Amazon ä¸ MovieLens ä¸ºä¾‹ã€‚


## ğŸ“¦ 1. ä¸‹è½½æ•°æ®é›†

ä»å…¬å¼€æºä¸‹è½½ Amazon æˆ– MovieLens æ•°æ®é›†ï¼š

```bash
# Amazon æ•°æ®é›†
python download_data.py --source amazon --dataset Sports_and_Outdoors

# MovieLens æ•°æ®é›†
python download_data.py --source movielens --dataset ml-1m
```


## ğŸ–¼ï¸ 2. ä¸‹è½½å›¾ç‰‡èµ„æº

è‹¥æ•°æ®åŒ…å«å›¾åƒå†…å®¹ï¼Œå¯è¿è¡Œä»¥ä¸‹å‘½ä»¤ä¸‹è½½å¯¹åº”å›¾ç‰‡ï¼š

```bash
# Amazon ç±»æ•°æ®é›†
python download_images.py --dataset_type amazon --dataset Sports_and_Outdoors

# MovieLens æ•°æ®é›†
python download_images.py --dataset_type movielens --dataset ml-1m
```



## ğŸ§¹ 3. æ•°æ®é¢„å¤„ç†

å¯¹åŸå§‹æ•°æ®æ‰§è¡Œæ¸…æ´—ã€æ ¼å¼åŒ–ä¸æ ‡å‡†åŒ–ï¼š

```bash
# Amazon
python process_data.py --dataset_type amazon --dataset Sports_and_Outdoors

# MovieLens
python process_data.py --dataset_type movielens --dataset ml-1m
```

### 3.1 æ„å»ºâ€œå¹²å‡€(ä¿ç•™)â€ä¸â€œé—å¿˜â€åˆ’åˆ†ï¼ˆä»… ML-1Mï¼‰

åŸºäºç”¨æˆ·ä¸»å¯¼ç±»å‹ï¼ˆä¾‹å¦‚ MovieLens çš„ä¸»å¯¼æµæ´¾ï¼‰è‡ªåŠ¨æ ‡è®°å¹¶åˆ é™¤â€œé”™è¯¯/å¾…é—å¿˜â€çš„äº¤äº’ï¼Œç”Ÿæˆï¼š

- å¹²å‡€åºåˆ—çš„è®­ç»ƒ/éªŒè¯/æµ‹è¯•ï¼šè¦†ç›– `../datasets/ml-1m/ml-1m.{train,valid,test}.jsonl`
- é—å¿˜è¯„æµ‹é›†ï¼š`../datasets/ml-1m/ml-1m.forget.jsonl`

ä½¿ç”¨æ–¹å¼ï¼ˆéœ€å…ˆå®Œæˆä¸Šä¸€æ­¥ `process_data.py` ä»¥ç”Ÿæˆ `ml-1m.inter.json` ä¸ `ml-1m.item.json`ï¼‰ï¼š

```bash
python split_ml1m_clean_forget.py \
    --dataset ml-1m \
    --dataset_root ../datasets \
    --threshold 0.9 \
    --max_history_len 50
```

è¯´æ˜ï¼š

- å¯¹æ¯ä¸ªç”¨æˆ·ç»Ÿè®¡å…¶äº¤äº’ä¸­å„â€œæµæ´¾â€çš„å æ¯”ï¼Œè‹¥æŸä¸€æµæ´¾å æ¯” â‰¥ é˜ˆå€¼ï¼ˆé»˜è®¤ 0.9ï¼‰ï¼Œåˆ™å°†â€œéè¯¥æµæ´¾â€çš„äº¤äº’æ ‡è®°ä¸º I_corr å¹¶ä»åºåˆ—ä¸­åˆ é™¤ï¼Œå¾—åˆ°â€œå¹²å‡€â€åºåˆ—ã€‚
- è®­ç»ƒ/éªŒè¯/æµ‹è¯•ä»…ç”±â€œå¹²å‡€â€åºåˆ—ç”Ÿæˆï¼›`ml-1m.forget.jsonl` åˆ™ä»¥â€œå¹²å‡€å†å²â€ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œç›®æ ‡ä¸ºè¢«åˆ é™¤çš„ I_corr ç‰©å“ï¼Œç”¨äºæ£€éªŒâ€œé—å¿˜æ•ˆæœâ€ã€‚


## ğŸ”  4. Embedding ç”Ÿæˆ

### ç”Ÿæˆæœ¬åœ° T5 æ–‡æœ¬åµŒå…¥ (PCA åˆ° 512d):

```bash
python process_embedding.py \
    --embedding_type text_local \
    --dataset Baby \
    --model_name_or_path sentence-transformers/sentence-t5-base \
    --pca_dim 512
```

### ç”Ÿæˆ OpenAI API æ–‡æœ¬åµŒå…¥:

```bash
python process_embedding.py \
    --embedding_type text_api \
    --dataset Baby \
    --sent_emb_model text-embedding-3-large \
    --pca_dim 512
```

### ç”Ÿæˆ CLIP å›¾åƒåµŒå…¥:


```bash
python process_embedding.py \
    --embedding_type image_clip \
    --dataset Baby \
    --clip_model_name /home/wj/peiyu/LLM_Models/openai-mirror/clip-vit-base-patch32 \
    --pca_dim 512
```

### ç”Ÿæˆ SASRec ååŒåµŒå…¥:

```bash
python process_embedding.py \
    --embedding_type cf_sasrec \
    --dataset Baby \
    --sasrec_hidden_dim 64 \
    --sasrec_epochs 30 \
    --pca_dim 0
```

### ç”Ÿæˆ Qwen-VL èåˆåµŒå…¥:

```bash
python process_embedding.py \
    --embedding_type vlm_fused \
    --dataset Baby \
    --vlm_model_name_or_path Qwen/Qwen3-VL-7B-Instruct \
    --batch_size 16  # æ³¨æ„è°ƒå° VLM batch size
    --pca_dim 512
```


## 5. æ¨¡æ€èåˆ

```bash
python fusion_embedding.py \
    --dataset Baby \
    --text_model_tag "text-embedding-3-large" \
    --image_model_tag "clip-vit-base-patch32" \
    --fusion_epochs 10 \
    --batch_size 4096 \
    --fusion_out_dim 512
```